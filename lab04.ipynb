{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse_incr\n",
    "from sklearn_crfsuite import CRF, metrics\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы был выбран корпус SynTagRus https://github.com/UniversalDependencies/UD_Russian-SynTagRus/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_toks = [\"SYM\", \"PUNCT\", \"X\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначально хотел привести данные в формат `предыдущий токен, текущий токен, следующий токен, POS-теги из pymorphy2`, но в таком случае разметка всех данных с помощью pymorphy2 проходила очень долго. Вместо этого принял решение использовать косвенные признаки: приставки и окончания слов, а также их длина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(sent) -> list:\n",
    "\n",
    "    new_sent = list()\n",
    "    tags = list\n",
    "    for i in range(len(sent)):\n",
    "        if sent[i][\"upos\"] not in stop_toks:\n",
    "            new_sent.append(sent[i])\n",
    "\n",
    "    temp = dict()\n",
    "    res = list()\n",
    "    for i in range(len(new_sent)):\n",
    "        temp = dict()\n",
    "        temp[\"current\"] = new_sent[i][\"lemma\"]\n",
    "        if i - 1 > 0 and i + 1 < len(new_sent):\n",
    "            temp[\"previous\"] = new_sent[i - 1][\"lemma\"]\n",
    "            temp[\"next\"] = new_sent[i + 1][\"lemma\"]\n",
    "        elif i - 1 <= 0 and i + 1 < len(new_sent):\n",
    "            temp[\"previous\"] = ''\n",
    "            temp[\"next\"] = new_sent[i + 1][\"lemma\"]\n",
    "        elif i - 1 > 0 and i + 1 >= len(new_sent):\n",
    "            temp[\"previous\"] = new_sent[i - 1][\"lemma\"]\n",
    "            temp[\"next\"] = ''\n",
    "        else:\n",
    "            temp[\"previous\"] = ''\n",
    "            temp[\"next\"] = ''\n",
    "        \n",
    "        temp[\"length\"] = len(new_sent[i][\"lemma\"])\n",
    "        temp[\"prefix[:4]\"] = new_sent[i][\"lemma\"][:4]\n",
    "        temp[\"prefix[:3]\"] = new_sent[i][\"lemma\"][:3]\n",
    "        temp[\"prefix[:2]\"] = new_sent[i][\"lemma\"][:2]\n",
    "        temp[\"postfix[-3:]\"] = new_sent[i][\"lemma\"][-3:]\n",
    "        temp[\"postfix[-2:]\"] = new_sent[i][\"lemma\"][-2:]\n",
    "        temp[\"postfix[-4:]\"] = new_sent[i][\"lemma\"][-4:]\n",
    "\n",
    "        res.append(temp)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(sent) -> list:\n",
    "    res = list()\n",
    "    for word in sent:\n",
    "        if word[\"upos\"] not in stop_toks:\n",
    "            res.append(word[\"upos\"])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ipath: str):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(ipath, 'r', encoding=\"utf-8\") as data_file:\n",
    "        for tokenlist in parse_incr(data_file):\n",
    "            X.append(get_features(tokenlist))\n",
    "            y.append(get_labels(tokenlist))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(os.getcwd(), \"deep\", \"UD_Russian-SynTagRus\", \"ru_syntagrus-ud-train.conllu\")\n",
    "test_path = os.path.join(os.getcwd(), \"deep\", \"UD_Russian-SynTagRus\", \"ru_syntagrus-ud-test.conllu\")\n",
    "dev_path = os.path.join(os.getcwd(), \"deep\", \"UD_Russian-SynTagRus\", \"ru_syntagrus-ud-dev.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(train_path)\n",
    "X_test, y_test = get_data(test_path)\n",
    "X_dev, y_dev = get_data(dev_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRF(\n",
    "    algorithm=\"lbfgs\",\n",
    "    c1 = 0.1,\n",
    "    c2 = 0.1,\n",
    "    max_iterations = 150,\n",
    "    all_possible_states=False,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 48814/48814 [00:11<00:00, 4171.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading dev data to CRFsuite: 100%|██████████| 6584/6584 [00:01<00:00, 4075.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holdout group: 2\n",
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 300009\n",
      "Seconds required: 2.969\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 150\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=3.05  loss=1574932.54 active=295282 precision=0.019  recall=0.067  F1=0.030  Acc(item/seq)=0.292 0.008  feature_norm=0.50\n",
      "Iter 2   time=0.99  loss=1495975.49 active=288451 precision=0.019  recall=0.067  F1=0.030  Acc(item/seq)=0.292 0.008  feature_norm=0.54\n",
      "Iter 3   time=1.18  loss=1482697.52 active=295165 precision=0.019  recall=0.067  F1=0.030  Acc(item/seq)=0.292 0.008  feature_norm=0.58\n",
      "Iter 4   time=1.12  loss=1459879.60 active=290466 precision=0.019  recall=0.067  F1=0.030  Acc(item/seq)=0.292 0.008  feature_norm=0.69\n",
      "Iter 5   time=1.44  loss=1425155.72 active=294887 precision=0.087  recall=0.088  F1=0.064  Acc(item/seq)=0.327 0.009  feature_norm=0.82\n",
      "Iter 6   time=1.00  loss=1385223.68 active=294030 precision=0.161  recall=0.154  F1=0.141  Acc(item/seq)=0.453 0.015  feature_norm=1.26\n",
      "Iter 7   time=1.32  loss=1338695.42 active=296837 precision=0.219  recall=0.156  F1=0.148  Acc(item/seq)=0.447 0.016  feature_norm=1.39\n",
      "Iter 8   time=1.39  loss=1234395.07 active=295620 precision=0.207  recall=0.174  F1=0.163  Acc(item/seq)=0.431 0.013  feature_norm=2.21\n",
      "Iter 9   time=1.37  loss=1072151.66 active=297434 precision=0.369  recall=0.281  F1=0.272  Acc(item/seq)=0.597 0.038  feature_norm=3.45\n",
      "Iter 10  time=1.13  loss=893728.15 active=297109 precision=0.386  recall=0.348  F1=0.334  Acc(item/seq)=0.659 0.057  feature_norm=6.23\n",
      "Iter 11  time=1.62  loss=737068.25 active=297539 precision=0.528  recall=0.367  F1=0.376  Acc(item/seq)=0.675 0.070  feature_norm=9.06\n",
      "Iter 12  time=1.13  loss=662361.70 active=298243 precision=0.563  recall=0.431  F1=0.451  Acc(item/seq)=0.725 0.091  feature_norm=10.78\n",
      "Iter 13  time=1.11  loss=531953.15 active=295418 precision=0.596  recall=0.521  F1=0.522  Acc(item/seq)=0.775 0.124  feature_norm=15.57\n",
      "Iter 14  time=1.55  loss=446750.65 active=296788 precision=0.700  recall=0.625  F1=0.633  Acc(item/seq)=0.828 0.183  feature_norm=18.03\n",
      "Iter 15  time=1.12  loss=398550.70 active=297091 precision=0.745  recall=0.602  F1=0.616  Acc(item/seq)=0.819 0.169  feature_norm=20.50\n",
      "Iter 16  time=1.10  loss=348237.45 active=297328 precision=0.726  recall=0.662  F1=0.681  Acc(item/seq)=0.853 0.222  feature_norm=22.48\n",
      "Iter 17  time=1.61  loss=314349.87 active=296929 precision=0.724  recall=0.692  F1=0.700  Acc(item/seq)=0.865 0.241  feature_norm=25.72\n",
      "Iter 18  time=1.91  loss=279606.00 active=296608 precision=0.732  recall=0.698  F1=0.710  Acc(item/seq)=0.865 0.263  feature_norm=28.71\n",
      "Iter 19  time=1.11  loss=249856.54 active=296009 precision=0.817  recall=0.702  F1=0.725  Acc(item/seq)=0.881 0.282  feature_norm=32.97\n",
      "Iter 20  time=1.12  loss=223575.44 active=295401 precision=0.815  recall=0.759  F1=0.781  Acc(item/seq)=0.889 0.311  feature_norm=36.05\n",
      "Iter 21  time=1.25  loss=199400.79 active=293494 precision=0.829  recall=0.794  F1=0.809  Acc(item/seq)=0.904 0.346  feature_norm=40.14\n",
      "Iter 22  time=1.37  loss=173465.57 active=285114 precision=0.838  recall=0.820  F1=0.827  Acc(item/seq)=0.916 0.389  feature_norm=44.70\n",
      "Iter 23  time=1.05  loss=153111.05 active=283271 precision=0.847  recall=0.828  F1=0.834  Acc(item/seq)=0.924 0.418  feature_norm=49.93\n",
      "Iter 24  time=1.02  loss=133175.01 active=281922 precision=0.855  recall=0.840  F1=0.846  Acc(item/seq)=0.933 0.457  feature_norm=56.52\n",
      "Iter 25  time=1.01  loss=119400.63 active=279290 precision=0.854  recall=0.853  F1=0.852  Acc(item/seq)=0.938 0.482  feature_norm=63.61\n",
      "Iter 26  time=1.20  loss=107761.73 active=279075 precision=0.862  recall=0.856  F1=0.859  Acc(item/seq)=0.945 0.511  feature_norm=67.69\n",
      "Iter 27  time=1.04  loss=94108.73 active=267191 precision=0.871  recall=0.862  F1=0.865  Acc(item/seq)=0.950 0.546  feature_norm=75.88\n",
      "Iter 28  time=1.40  loss=81841.37 active=256232 precision=0.876  recall=0.869  F1=0.872  Acc(item/seq)=0.956 0.579  feature_norm=84.83\n",
      "Iter 29  time=1.31  loss=74684.32 active=233585 precision=0.876  recall=0.882  F1=0.878  Acc(item/seq)=0.962 0.614  feature_norm=98.79\n",
      "Iter 30  time=2.11  loss=65461.17 active=235055 precision=0.883  recall=0.884  F1=0.883  Acc(item/seq)=0.966 0.652  feature_norm=102.18\n",
      "Iter 31  time=1.40  loss=61414.81 active=226623 precision=0.886  recall=0.885  F1=0.885  Acc(item/seq)=0.967 0.663  feature_norm=106.17\n",
      "Iter 32  time=1.41  loss=53789.57 active=210429 precision=0.892  recall=0.888  F1=0.889  Acc(item/seq)=0.971 0.694  feature_norm=121.80\n",
      "Iter 33  time=1.14  loss=51843.86 active=199917 precision=0.893  recall=0.888  F1=0.890  Acc(item/seq)=0.970 0.678  feature_norm=128.50\n",
      "Iter 34  time=1.35  loss=47556.43 active=197886 precision=0.895  recall=0.892  F1=0.893  Acc(item/seq)=0.974 0.713  feature_norm=131.86\n",
      "Iter 35  time=1.50  loss=44675.80 active=189510 precision=0.896  recall=0.896  F1=0.896  Acc(item/seq)=0.976 0.729  feature_norm=136.99\n",
      "Iter 36  time=1.78  loss=41488.18 active=170474 precision=0.898  recall=0.897  F1=0.897  Acc(item/seq)=0.978 0.750  feature_norm=145.73\n",
      "Iter 37  time=1.09  loss=38906.75 active=161642 precision=0.963  recall=0.922  F1=0.928  Acc(item/seq)=0.979 0.757  feature_norm=151.39\n",
      "Iter 38  time=1.11  loss=36928.10 active=160016 precision=0.967  recall=0.922  F1=0.930  Acc(item/seq)=0.981 0.775  feature_norm=154.30\n",
      "Iter 39  time=1.31  loss=35267.10 active=154034 precision=0.968  recall=0.927  F1=0.937  Acc(item/seq)=0.981 0.784  feature_norm=157.19\n",
      "Iter 40  time=1.28  loss=33616.02 active=150668 precision=0.968  recall=0.929  F1=0.938  Acc(item/seq)=0.982 0.793  feature_norm=160.31\n",
      "Iter 41  time=1.11  loss=32226.31 active=143944 precision=0.969  recall=0.929  F1=0.939  Acc(item/seq)=0.982 0.794  feature_norm=164.80\n",
      "Iter 42  time=1.08  loss=31514.70 active=141627 precision=0.970  recall=0.931  F1=0.941  Acc(item/seq)=0.984 0.812  feature_norm=168.32\n",
      "Iter 43  time=1.26  loss=30558.91 active=141012 precision=0.970  recall=0.931  F1=0.940  Acc(item/seq)=0.984 0.808  feature_norm=169.86\n",
      "Iter 44  time=1.34  loss=30002.11 active=137670 precision=0.970  recall=0.931  F1=0.940  Acc(item/seq)=0.984 0.808  feature_norm=170.89\n",
      "Iter 45  time=1.25  loss=29091.67 active=130006 precision=0.970  recall=0.931  F1=0.941  Acc(item/seq)=0.984 0.810  feature_norm=173.11\n",
      "Iter 46  time=1.03  loss=28685.98 active=115229 precision=0.971  recall=0.932  F1=0.941  Acc(item/seq)=0.984 0.815  feature_norm=176.46\n",
      "Iter 47  time=1.00  loss=27884.28 active=111247 precision=0.970  recall=0.931  F1=0.941  Acc(item/seq)=0.984 0.813  feature_norm=177.21\n",
      "Iter 48  time=1.10  loss=27554.11 active=109798 precision=0.971  recall=0.931  F1=0.941  Acc(item/seq)=0.984 0.813  feature_norm=178.02\n",
      "Iter 49  time=1.07  loss=26952.05 active=102551 precision=0.958  recall=0.940  F1=0.945  Acc(item/seq)=0.985 0.815  feature_norm=184.66\n",
      "Iter 50  time=1.11  loss=26465.75 active=102233 precision=0.960  recall=0.938  F1=0.945  Acc(item/seq)=0.985 0.818  feature_norm=184.98\n",
      "Iter 51  time=1.03  loss=26239.86 active=101992 precision=0.960  recall=0.937  F1=0.945  Acc(item/seq)=0.985 0.816  feature_norm=185.60\n",
      "Iter 52  time=1.05  loss=26029.07 active=99957 precision=0.960  recall=0.938  F1=0.945  Acc(item/seq)=0.985 0.816  feature_norm=186.68\n",
      "Iter 53  time=3.19  loss=25384.18 active=93845 precision=0.958  recall=0.931  F1=0.939  Acc(item/seq)=0.985 0.815  feature_norm=190.97\n",
      "Iter 54  time=4.72  loss=25380.52 active=92531 precision=0.958  recall=0.931  F1=0.939  Acc(item/seq)=0.985 0.815  feature_norm=191.56\n",
      "Iter 55  time=0.99  loss=24964.00 active=92213 precision=0.958  recall=0.931  F1=0.939  Acc(item/seq)=0.985 0.816  feature_norm=192.58\n",
      "Iter 56  time=1.04  loss=24685.51 active=90569 precision=0.958  recall=0.932  F1=0.939  Acc(item/seq)=0.985 0.816  feature_norm=194.11\n",
      "Iter 57  time=1.06  loss=24327.35 active=87191 precision=0.959  recall=0.930  F1=0.939  Acc(item/seq)=0.985 0.816  feature_norm=196.34\n",
      "Iter 58  time=2.12  loss=24129.32 active=86636 precision=0.958  recall=0.932  F1=0.939  Acc(item/seq)=0.985 0.818  feature_norm=197.24\n",
      "Iter 59  time=1.40  loss=23917.72 active=86030 precision=0.958  recall=0.932  F1=0.939  Acc(item/seq)=0.985 0.817  feature_norm=198.28\n",
      "Iter 60  time=1.65  loss=23696.06 active=84179 precision=0.958  recall=0.931  F1=0.939  Acc(item/seq)=0.985 0.817  feature_norm=199.95\n",
      "Iter 61  time=2.01  loss=23476.08 active=81925 precision=0.958  recall=0.933  F1=0.940  Acc(item/seq)=0.985 0.817  feature_norm=201.70\n",
      "Iter 62  time=1.41  loss=23261.92 active=79311 precision=0.959  recall=0.931  F1=0.939  Acc(item/seq)=0.985 0.819  feature_norm=203.52\n",
      "Iter 63  time=0.98  loss=23099.54 active=78956 precision=0.958  recall=0.932  F1=0.939  Acc(item/seq)=0.985 0.819  feature_norm=203.83\n",
      "Iter 64  time=1.11  loss=22949.11 active=77993 precision=0.958  recall=0.932  F1=0.939  Acc(item/seq)=0.985 0.818  feature_norm=204.29\n",
      "Iter 65  time=1.27  loss=22741.96 active=76515 precision=0.958  recall=0.931  F1=0.939  Acc(item/seq)=0.985 0.818  feature_norm=205.26\n",
      "Iter 66  time=1.96  loss=22643.25 active=75628 precision=0.958  recall=0.933  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=205.50\n",
      "Iter 67  time=1.33  loss=22518.86 active=75289 precision=0.958  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.820  feature_norm=205.88\n",
      "Iter 68  time=1.63  loss=22390.62 active=74325 precision=0.959  recall=0.932  F1=0.939  Acc(item/seq)=0.985 0.820  feature_norm=206.46\n",
      "Iter 69  time=1.04  loss=22290.59 active=72569 precision=0.958  recall=0.933  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=207.49\n",
      "Iter 70  time=1.06  loss=22205.36 active=72096 precision=0.958  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.820  feature_norm=207.98\n",
      "Iter 71  time=1.03  loss=22148.02 active=72144 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.821  feature_norm=208.11\n",
      "Iter 72  time=1.12  loss=22094.42 active=71667 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.821  feature_norm=208.33\n",
      "Iter 73  time=1.18  loss=22018.52 active=70840 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=208.60\n",
      "Iter 74  time=1.22  loss=21984.45 active=69556 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=209.13\n",
      "Iter 75  time=1.12  loss=21914.29 active=69690 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=208.95\n",
      "Iter 76  time=1.10  loss=21886.34 active=69265 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=208.99\n",
      "Iter 77  time=1.05  loss=21828.62 active=68340 precision=0.958  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=209.17\n",
      "Iter 78  time=0.95  loss=21780.87 active=67722 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=209.17\n",
      "Iter 79  time=1.09  loss=21743.12 active=67352 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=209.34\n",
      "Iter 80  time=1.03  loss=21707.96 active=67102 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=209.39\n",
      "Iter 81  time=1.16  loss=21667.61 active=66427 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=209.38\n",
      "Iter 82  time=0.98  loss=21636.03 active=65504 precision=0.959  recall=0.931  F1=0.939  Acc(item/seq)=0.985 0.821  feature_norm=209.56\n",
      "Iter 83  time=1.13  loss=21592.57 active=65474 precision=0.959  recall=0.933  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=209.52\n",
      "Iter 84  time=0.96  loss=21568.11 active=65120 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=209.55\n",
      "Iter 85  time=1.01  loss=21533.62 active=64505 precision=0.958  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.822  feature_norm=209.56\n",
      "Iter 86  time=0.98  loss=21505.91 active=64131 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=209.74\n",
      "Iter 87  time=1.04  loss=21472.45 active=64031 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=209.77\n",
      "Iter 88  time=1.03  loss=21450.05 active=63801 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=209.80\n",
      "Iter 89  time=1.14  loss=21431.26 active=63320 precision=0.959  recall=0.933  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=209.83\n",
      "Iter 90  time=1.32  loss=21392.92 active=63201 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=209.93\n",
      "Iter 91  time=1.39  loss=21369.54 active=62973 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=209.94\n",
      "Iter 92  time=1.47  loss=21354.36 active=62761 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=209.97\n",
      "Iter 93  time=1.04  loss=21326.78 active=62685 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=210.04\n",
      "Iter 94  time=1.00  loss=21306.45 active=62463 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=210.09\n",
      "Iter 95  time=1.17  loss=21286.76 active=62257 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.19\n",
      "Iter 96  time=1.10  loss=21270.34 active=62079 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=210.23\n",
      "Iter 97  time=1.13  loss=21249.19 active=61915 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.35\n",
      "Iter 98  time=1.43  loss=21232.97 active=61764 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.40\n",
      "Iter 99  time=1.15  loss=21217.36 active=61604 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.50\n",
      "Iter 100 time=1.00  loss=21204.70 active=61468 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.56\n",
      "Iter 101 time=1.18  loss=21190.55 active=61302 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=210.67\n",
      "Iter 102 time=1.17  loss=21177.41 active=61193 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.74\n",
      "Iter 103 time=1.36  loss=21163.27 active=61141 precision=0.958  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=210.83\n",
      "Iter 104 time=1.22  loss=21154.83 active=61011 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.88\n",
      "Iter 105 time=1.56  loss=21143.55 active=60908 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=210.97\n",
      "Iter 106 time=1.55  loss=21132.90 active=60807 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.02\n",
      "Iter 107 time=1.31  loss=21123.52 active=60769 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.11\n",
      "Iter 108 time=1.23  loss=21112.80 active=60645 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.823  feature_norm=211.16\n",
      "Iter 109 time=1.28  loss=21105.85 active=60558 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.22\n",
      "Iter 110 time=1.27  loss=21096.25 active=60463 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.26\n",
      "Iter 111 time=1.21  loss=21089.07 active=60430 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.31\n",
      "Iter 112 time=1.22  loss=21079.73 active=60334 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.34\n",
      "Iter 113 time=1.11  loss=21072.74 active=60298 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.38\n",
      "Iter 114 time=1.20  loss=21065.91 active=60230 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.41\n",
      "Iter 115 time=1.27  loss=21057.66 active=60166 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.44\n",
      "Iter 116 time=1.36  loss=21051.30 active=60074 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.46\n",
      "Iter 117 time=1.37  loss=21043.59 active=60040 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.50\n",
      "Iter 118 time=1.46  loss=21038.58 active=59967 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.51\n",
      "Iter 119 time=1.32  loss=21031.49 active=59916 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.54\n",
      "Iter 120 time=1.17  loss=21025.80 active=59833 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.56\n",
      "Iter 121 time=1.40  loss=21019.32 active=59816 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.58\n",
      "Iter 122 time=1.31  loss=21014.75 active=59751 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.59\n",
      "Iter 123 time=1.26  loss=21008.15 active=59688 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.62\n",
      "Iter 124 time=1.23  loss=21003.51 active=59606 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.64\n",
      "Iter 125 time=1.25  loss=20997.27 active=59593 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.68\n",
      "Iter 126 time=1.10  loss=20992.80 active=59559 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.68\n",
      "Iter 127 time=1.11  loss=20986.65 active=59517 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.71\n",
      "Iter 128 time=1.27  loss=20981.76 active=59470 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.71\n",
      "Iter 129 time=1.29  loss=20975.91 active=59429 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.72\n",
      "Iter 130 time=1.27  loss=20971.37 active=59397 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.824  feature_norm=211.73\n",
      "Iter 131 time=1.27  loss=20965.92 active=59338 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.73\n",
      "Iter 132 time=1.39  loss=20961.10 active=59326 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.73\n",
      "Iter 133 time=1.22  loss=20955.84 active=59299 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.73\n",
      "Iter 134 time=1.33  loss=20949.70 active=59237 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.75\n",
      "Iter 135 time=1.37  loss=20945.33 active=59203 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.73\n",
      "Iter 136 time=1.21  loss=20939.84 active=59169 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.72\n",
      "Iter 137 time=1.38  loss=20934.76 active=59166 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.72\n",
      "Iter 138 time=1.30  loss=20929.22 active=59119 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.71\n",
      "Iter 139 time=1.32  loss=20923.39 active=59072 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.70\n",
      "Iter 140 time=1.22  loss=20917.02 active=59055 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.69\n",
      "Iter 141 time=1.23  loss=20912.30 active=59025 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.67\n",
      "Iter 142 time=1.19  loss=20905.69 active=59013 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.66\n",
      "Iter 143 time=1.32  loss=20900.16 active=58988 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.64\n",
      "Iter 144 time=1.21  loss=20893.61 active=58948 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.825  feature_norm=211.63\n",
      "Iter 145 time=1.33  loss=20888.49 active=58910 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.59\n",
      "Iter 146 time=1.45  loss=20881.11 active=58882 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.57\n",
      "Iter 147 time=1.50  loss=20875.42 active=58843 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.54\n",
      "Iter 148 time=1.64  loss=20868.73 active=58800 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.51\n",
      "Iter 149 time=1.52  loss=20862.60 active=58759 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.985 0.824  feature_norm=211.47\n",
      "Iter 150 time=1.19  loss=20856.63 active=58714 precision=0.959  recall=0.932  F1=0.940  Acc(item/seq)=0.986 0.825  feature_norm=211.44\n",
      "================================================\n",
      "Label      Precision    Recall     F1    Support\n",
      "-------  -----------  --------  -----  ---------\n",
      "ADJ            0.995     0.996  0.996      11222\n",
      "ADP            0.998     0.999  0.999      10585\n",
      "ADV            0.982     0.968  0.975       6165\n",
      "AUX            0.895     0.898  0.896       1108\n",
      "CCONJ          0.953     0.976  0.964       4410\n",
      "DET            0.995     0.984  0.990       3085\n",
      "INTJ           0.800     0.364  0.500         11\n",
      "NOUN           0.996     0.997  0.997      27974\n",
      "NUM            0.951     0.974  0.963       1829\n",
      "PART           0.956     0.921  0.939       3875\n",
      "PRON           0.980     0.976  0.978       5598\n",
      "PROPN          0.995     0.986  0.990       4438\n",
      "SCONJ          0.900     0.946  0.923       2258\n",
      "VERB           0.991     0.991  0.991      13078\n",
      "_              1.000     1.000  1.000        204\n",
      "------------------------------------------------\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 195.418\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 58714 (300009)\n",
      "Number of active attributes: 35594 (166884)\n",
      "Number of active labels: 15 (15)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.089\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=150, verbose=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(model.classes_)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADP',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'PROPN',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'NUM',\n",
       " 'NOUN']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADP',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'PROPN',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'NUM',\n",
       " 'NOUN']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NOUN      0.997     0.996     0.997     28663\n",
      "         ADJ      0.993     0.998     0.995     10992\n",
      "       PROPN      0.996     0.991     0.993      4754\n",
      "         AUX      0.913     0.935     0.924      1042\n",
      "        VERB      0.993     0.994     0.994     13048\n",
      "         ADP      0.999     0.999     0.999     11516\n",
      "         ADV      0.977     0.972     0.975      5849\n",
      "       CCONJ      0.955     0.976     0.966      4156\n",
      "        PART      0.954     0.924     0.939      3322\n",
      "        PRON      0.986     0.978     0.982      5024\n",
      "         DET      0.995     0.989     0.992      2755\n",
      "       SCONJ      0.909     0.946     0.927      2048\n",
      "         NUM      0.976     0.983     0.980      2691\n",
      "           _      0.000     0.000     0.000         0\n",
      "        INTJ      1.000     0.273     0.429        11\n",
      "\n",
      "   micro avg      0.988     0.988     0.988     95871\n",
      "   macro avg      0.910     0.864     0.873     95871\n",
      "weighted avg      0.988     0.988     0.988     95871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_test, y_pred, labels, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
